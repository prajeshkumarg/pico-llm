{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4e7f9b56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e7f9b56",
        "outputId": "c2de6238-8d67-4ba1-9593-7b5a7888bb34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports done.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset\n",
        "import tiktoken\n",
        "\n",
        "print('All imports done.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c3af9ba3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3af9ba3",
        "outputId": "ea41244f-1f08-41cb-d862-b5849cc80439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2e8c461",
      "metadata": {
        "id": "d2e8c461"
      },
      "source": [
        "### Hyperparameters\n",
        "\n",
        "For Data\n",
        "1. block_size\n",
        "2. train_subset_size\n",
        "3. batch_size\n",
        "4. tinystories_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e5735ba",
      "metadata": {
        "id": "7e5735ba"
      },
      "outputs": [],
      "source": [
        "# Data parameters\n",
        "block_size = 128  # Sequence length for training\n",
        "train_subset_size = 20000  # Number of samples to use from TinyStories\n",
        "batch_size = 32\n",
        "\n",
        "tinystories_weight = 1  # Proportion of TinyStories in mixed dataset (0.0 to skip)\n",
        "\n",
        "# Training parameters\n",
        "epochs = 2\n",
        "learning_rate = 1e-3\n",
        "log_steps = 100\n",
        "sample_interval = 30  # seconds between text samples during training\n",
        "max_steps_per_epoch = None  # Set to an int for quick tests\n",
        "\n",
        "# Prompt for text generation\n",
        "default_prompt = \"Once upon a time\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "acc1dea7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432,
          "referenced_widgets": [
            "66e52c9ad2134764a03254a0eebca7cf",
            "e34cc27b6cd24fb2a527d6df8ef0ba9c",
            "5c2be75053c94d20b20a0bd62eba9a64",
            "036acffdf74a4fdc99617dd6cc05eea8",
            "94d2b275c7cc4df3b4c5e4839dc161b9",
            "af23ee0a33294fdb9cf4597c6c7661fe",
            "4f3f1d350ead494e91c1d733581579b1",
            "b44b30b879a7404699cb9695c9c5bb1b",
            "9887737d53f14cc9b28397b4cc951b74",
            "2c8cb15e16b146b9a1a37ef5aa19da4a",
            "62430952b68b472db0ee6490f7a7b92d",
            "78220c103dd74f8e873e03fd72c8f655",
            "e4d41f3479484159b4fc6d6c0c4edcb8",
            "1b022f670e5043ebb4eee1c1674caa65",
            "3c6ab15395ed4434b93a333abcc5a6a7",
            "f9cc885d81ca400fb49121ffac8b1a65",
            "86b8a70efe954e8d80e83fb365074b89",
            "c6f860a596374245a7c1b273fa0f9858",
            "77291f40fb5a4f44867856164211b44c",
            "c61dffc80fcf44719801976e649eba74",
            "17a202a17286477a9c47800dade1c362",
            "a80321d5ead74f4b80b0a9b77ed95b19",
            "221dbda07b384a1c95c897ae070b789a",
            "bb6bea8dbddc48a293928beba6c01b0d",
            "73bf96ea610d4e49a264a1eac9014f08",
            "8890e10c4def4f919923203782600a5e",
            "acfd1299cc0f4077abf48b6ecf503291",
            "669cfb8a3c994a709c6446b00104fc7c",
            "1d9701d8d3da44fb8b4c46a27b0fba63",
            "49d3342030c8400eab35fb3db86768d1",
            "eea5cdf2722e4dfc909a24922c020b07",
            "67edf1bbcc60450a96f92bd436a1afab",
            "020ef10fb41649788c53e45813a8787d",
            "a78c005be0684505bf9ff88385ea0447",
            "25cac51333f94863b80e75f051bc8077",
            "d1c349841e90442ab718791174a4659b",
            "5cdbcefcc5884587ab826e604da123fa",
            "11eae792432d4c918ef18912ad9c9321",
            "2831234b9b9d48d9b11ccc462c1dda4f",
            "e0cc0b4df9c046d3be94c5bd1cfabdda",
            "c2a2aedb0b724b35a4f40b899ff1b408",
            "7894db6cff7e4c87b662c473da461ab5",
            "333dcf79a85d47bbb75a4e52bfd04dac",
            "1a13eb7a07474a9a899c8af0e7f81e7f",
            "702387e1726545f0a7db00ff705cd047",
            "bc6746699ba5444eb0791d4d631756e0",
            "f85475169dec4668b8f210f731ddd228",
            "40819a6d95074162b5c53df893294773",
            "55a3cb99f72146e5bb07680860b769be",
            "1e53239fa43946178d9a2affc4c3e576",
            "52ede7da5389408596414f2b55133ddd",
            "9e75d090d0fb4b20bdca3cc73a37f7cb",
            "6f71d1dffd584e04bc47c180e863bb9d",
            "f22631c596be4990ae2ad554891a1b16",
            "9347451c76264398b71f4085b0901e45",
            "779f05d9d0a84b89b18addd09e16b5ce",
            "df5d4eb344d74623aaba9664caf42287",
            "40b2c021efdf4c6aacc29939a96e249d",
            "166cc2748c92466fa3762aa7812e7c36",
            "089f4f2bb5e54d6882315dea3e51c66e",
            "4dfd9a3aca714045a018375def9a7966",
            "a1f6f14201c143bb84a166b87bf6c753",
            "64f8c7138c8947a2902dea2c76a70869",
            "73acd8abc3214686b7bddbbf0f81315e",
            "e38cefe9c8ca44cfb1a1a38a6176998f",
            "f675f90cca99433d8369eb0915715377",
            "34a0ae6d14524c55893ebde493de770d",
            "f6a6ae61407141f389e34750e47a299e",
            "3757dfdf19324577964dc8a50d599107",
            "e04cca50132a4f86a5c87029b572d7e6",
            "9a0262a354cb41bf9c2e931fe1ce59ac",
            "a5fdab7656c24bad993d54ccee4babf8",
            "154edf7afed0466a87d84d9b62df93a3",
            "6b518c781a50491e99fd456c0c8a38c0",
            "bdc21573d83b42a380f33c2dc6e4bf6b",
            "bcf7cb54a690453194f16ace39a33cc8",
            "401a7df54bd446f1a9c68846de58519f",
            "47da470abad64013b165f8b8f4b83967",
            "fcb1b03cf85942a3aabf010166bb23fe",
            "1ad90c3321874b0b97d225c8dbca7a60",
            "4cf351a87bf64bbaaf20366ef1c0c1f3",
            "dc9e35a64f51446d9a29ffafe06db53d",
            "fe5097dec301403bbd19080d604051d0",
            "c7dd1f6e7919413da843a921c22c0fd5",
            "e6da3e8ae8674caca240eac85e9ef57c",
            "ac2b45a68577425997b14cea8e60ca7f",
            "9d45cdc1b8da451bbcc2d1a9284819d4",
            "f4afba5beab5421383d94856a9d15dc1"
          ]
        },
        "id": "acc1dea7",
        "outputId": "6a57119f-58ee-4438-f0b6-3c991a030d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading TinyStories from huggingface with weight=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66e52c9ad2134764a03254a0eebca7cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00004-2d5a1467fff108(…):   0%|          | 0.00/249M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78220c103dd74f8e873e03fd72c8f655"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00004-5852b56a2bd28f(…):   0%|          | 0.00/248M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "221dbda07b384a1c95c897ae070b789a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00002-of-00004-a26307300439e9(…):   0%|          | 0.00/246M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a78c005be0684505bf9ff88385ea0447"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00003-of-00004-d243063613e5a0(…):   0%|          | 0.00/248M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "702387e1726545f0a7db00ff705cd047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00000-of-00001-869c898b5(…):   0%|          | 0.00/9.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "779f05d9d0a84b89b18addd09e16b5ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34a0ae6d14524c55893ebde493de770d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47da470abad64013b165f8b8f4b83967"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TinyStories sequences: 20000\n"
          ]
        }
      ],
      "source": [
        "# Load tokenizer\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "vocab_size = enc.n_vocab\n",
        "\n",
        "# Load TinyStories dataset\n",
        "tinystories_seqs = []\n",
        "if tinystories_weight > 0.0:\n",
        "    print(f\"Loading TinyStories from huggingface with weight={tinystories_weight}...\")\n",
        "    dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
        "    train_dataset = dataset.select(range(train_subset_size))\n",
        "    for sample in train_dataset:\n",
        "        text = sample['text']\n",
        "        tokens = enc.encode(text)\n",
        "        tokens = tokens[:block_size]\n",
        "        if len(tokens) > 0:\n",
        "            tinystories_seqs.append(tokens)\n",
        "    print(f\"TinyStories sequences: {len(tinystories_seqs)}\")\n",
        "else:\n",
        "    print(\"TinyStories weight=0 => skipping TinyStories.\")\n",
        "other_seqs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4f926891",
      "metadata": {
        "id": "4f926891"
      },
      "outputs": [],
      "source": [
        "class MixedSequenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tinystories_seqs, other_seqs, p_tiny: float):\n",
        "        super().__init__()\n",
        "        self.tinystories_seqs = tinystories_seqs\n",
        "        self.other_seqs = other_seqs\n",
        "        self.p_tiny = p_tiny\n",
        "        self.has_tinystories = (len(self.tinystories_seqs) > 0)\n",
        "        self.has_other = (len(self.other_seqs) > 0)\n",
        "        self.total_length = len(self.tinystories_seqs) + len(self.other_seqs)\n",
        "        if self.total_length == 0:\n",
        "            raise ValueError(\"No data found! Both TinyStories and other sets are empty.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        import random\n",
        "        r = random.random()\n",
        "        if self.has_tinystories and self.has_other:\n",
        "            if r < self.p_tiny:\n",
        "                i = random.randint(0, len(self.tinystories_seqs) - 1)\n",
        "                seq = self.tinystories_seqs[i]\n",
        "            else:\n",
        "                i = random.randint(0, len(self.other_seqs) - 1)\n",
        "                seq = self.other_seqs[i]\n",
        "        elif self.has_tinystories:\n",
        "            i = random.randint(0, len(self.tinystories_seqs) - 1)\n",
        "            seq = self.tinystories_seqs[i]\n",
        "        else:\n",
        "            i = random.randint(0, len(self.other_seqs) - 1)\n",
        "            seq = self.other_seqs[i]\n",
        "        return torch.tensor(seq, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4b498ac3",
      "metadata": {
        "id": "4b498ac3"
      },
      "outputs": [],
      "source": [
        "def seq_collate_fn(batch):\n",
        "    max_len = max(len(seq) for seq in batch)\n",
        "    batch_size = len(batch)\n",
        "    padded = torch.zeros(max_len, batch_size, dtype=torch.long)\n",
        "    for i, seq in enumerate(batch):\n",
        "        seq_len = seq.size(0)\n",
        "        padded[:seq_len, i] = seq\n",
        "    return padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "453a9b3f",
      "metadata": {
        "id": "453a9b3f"
      },
      "outputs": [],
      "source": [
        "# Create dataset and loader\n",
        "p_tiny = tinystories_weight\n",
        "combined_dataset = MixedSequenceDataset(\n",
        "    tinystories_seqs=tinystories_seqs,\n",
        "    other_seqs=other_seqs,\n",
        "    p_tiny=p_tiny\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f5bc3495",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5bc3495",
        "outputId": "dbfe2244-1c39-4719-dbfd-b585f3ab984f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "combined_dataset.total_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "18531162",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18531162",
        "outputId": "7329eb5e-f393-4abf-f818-c27e7fda0e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoader ready. Vocab size: 50257\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    combined_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=seq_collate_fn\n",
        ")\n",
        "\n",
        "print(\"DataLoader ready. Vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b108a7d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b108a7d8",
        "outputId": "ea3dbea9-88b1-4447-df7e-3cf004bce12a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading TinyStories val subset (20000:22000)...\n",
            "TinyStories VAL sequences: 2000\n",
            "Validation DataLoader ready. Num val sequences: 2000\n"
          ]
        }
      ],
      "source": [
        "### Validation\n",
        "# Validation data (next 2000 samples)\n",
        "val_subset_size = train_subset_size // 10  # 2000\n",
        "tinystories_val_seqs = []\n",
        "print(f\"Loading TinyStories val subset ({train_subset_size}:{train_subset_size + val_subset_size})...\")\n",
        "dataset_val = dataset.select(range(train_subset_size, train_subset_size + val_subset_size))  # 20000..21999\n",
        "for sample in dataset_val:\n",
        "    text = sample[\"text\"]\n",
        "    tokens = enc.encode(text)\n",
        "    tokens = tokens[:block_size]\n",
        "    if len(tokens) > 0:\n",
        "        tinystories_val_seqs.append(tokens)\n",
        "print(f\"TinyStories VAL sequences: {len(tinystories_val_seqs)}\")\n",
        "\n",
        "# Create validation dataset and DataLoader\n",
        "\n",
        "val_p_tiny = tinystories_weight  # same mixing proportion as training\n",
        "\n",
        "val_dataset = MixedSequenceDataset(\n",
        "    tinystories_seqs=tinystories_val_seqs,\n",
        "    other_seqs=[],          # no other validation data for now\n",
        "    p_tiny=val_p_tiny\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=seq_collate_fn\n",
        ")\n",
        "\n",
        "print(\"Validation DataLoader ready. Num val sequences:\", len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "64b72f77",
      "metadata": {
        "id": "64b72f77"
      },
      "outputs": [],
      "source": [
        "def compute_next_token_loss(logits, tokens_seq):\n",
        "    '''\n",
        "    logits: (seq_len, batch, vocab_size)\n",
        "    tokens_seq: (seq_len, batch)\n",
        "    Computes cross-entropy loss for next-token prediction.\n",
        "    '''\n",
        "    seq_len, batch = tokens_seq.shape\n",
        "    # Predict next token: input t => predict t+1\n",
        "    logits = logits[:-1]  # (seq_len-1, batch, vocab_size)\n",
        "    targets = tokens_seq[1:]  # (seq_len-1, batch)\n",
        "    loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.reshape(-1))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class KGramMLPSeqModelEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    K-gram MLP using nn.Embedding instead of one-hot vectors.\n",
        "    For each position t: take last k tokens → embedding(L2 norm?) → flatten → MLP → vocab logits.\n",
        "    Output: (seq_len, batch, vocab_size)\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, k=3, embed_size=256, num_inner_layers=1,\n",
        "                 chunk_size=1, activation=nn.SiLU):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_size = embed_size\n",
        "        self.num_inner_layers = num_inner_layers\n",
        "        self.chunk_size = chunk_size\n",
        "        self.activation = activation\n",
        "\n",
        "        # Embedding layer replacing one-hot\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        # MLP: input = k * embed_size\n",
        "        layers = [nn.Linear(k * embed_size, embed_size), self.activation()]\n",
        "        for _ in range(num_inner_layers):\n",
        "            layers += [nn.Linear(embed_size, embed_size), self.activation()]\n",
        "        layers.append(nn.Linear(embed_size, vocab_size))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, tokens_seq):\n",
        "        seq_len, batch_size = tokens_seq.shape\n",
        "        outputs = []\n",
        "\n",
        "        start = 0\n",
        "        while start < seq_len:\n",
        "            end = min(start + self.chunk_size, seq_len)\n",
        "            block_outputs = []\n",
        "\n",
        "            for t in range(start, end):\n",
        "                batch_logits = []\n",
        "\n",
        "                for b in range(batch_size):\n",
        "                    # Collect last k token IDs\n",
        "                    if t < self.k:\n",
        "                        pad_len = self.k - t\n",
        "                        context_ids = [0] * pad_len + tokens_seq[:t, b].tolist()\n",
        "                    else:\n",
        "                        context_ids = tokens_seq[t - self.k:t, b].tolist()\n",
        "\n",
        "                    # Get embeddings for k tokens\n",
        "                    context_embed = self.embedding(\n",
        "                        torch.tensor(context_ids, dtype=torch.long, device=tokens_seq.device)\n",
        "                    )  # (k, embed_size)\n",
        "\n",
        "                    # Flatten\n",
        "                    context_flat = context_embed.flatten().unsqueeze(0)  # (1, k*embed_size)\n",
        "\n",
        "                    # MLP to logits\n",
        "                    logits_b = self.net(context_flat)\n",
        "                    batch_logits.append(logits_b)\n",
        "\n",
        "                block_outputs.append(torch.cat(batch_logits, dim=0).unsqueeze(0))\n",
        "\n",
        "            block_outputs = torch.cat(block_outputs, dim=0)  # (sub_seq, batch, vocab)\n",
        "            outputs.append(block_outputs)\n",
        "\n",
        "            start = end\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=0)\n",
        "        return outputs  # (seq_len, batch, vocab_size)\n"
      ],
      "metadata": {
        "id": "GKBUKm_Bmvon"
      },
      "id": "GKBUKm_Bmvon",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7de17cf2",
      "metadata": {
        "id": "7de17cf2"
      },
      "outputs": [],
      "source": [
        "class KGramMLPSeqModel(nn.Module):\n",
        "    \"\"\"\n",
        "    For each position t in [0..seq_len-1], gather the last k tokens => one-hot => MLP => logits.\n",
        "    Return (seq_len, batch, vocab_size).\n",
        "\n",
        "    Potentially very large memory usage for big vocab or seq_len. chunk_size helps mitigate overhead.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, k=3, embed_size=1024, num_inner_layers=1, chunk_size=1, activation=nn.SiLU):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_size = embed_size\n",
        "        self.num_inner_layers = num_inner_layers\n",
        "        self.chunk_size = chunk_size\n",
        "        # fill in\n",
        "        self.activation = activation\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.k * self.vocab_size, self.embed_size),\n",
        "            self.activation(),\n",
        "            *[\n",
        "                layer for _ in range(self.num_inner_layers) for layer in (\n",
        "                    nn.Linear(self.embed_size, self.embed_size),\n",
        "                    self.activation()\n",
        "                )],\n",
        "                nn.Linear(self.embed_size, self.vocab_size))\n",
        "\n",
        "    def forward(self, tokens_seq):\n",
        "        \"\"\"\n",
        "        tokens_seq: (seq_len, batch)\n",
        "        return: (seq_len, batch, vocab_size)\n",
        "        We'll do a loop over time steps. chunk_size can reduce overhead.\n",
        "        \"\"\"\n",
        "        seq_len, batch_size = tokens_seq.shape\n",
        "        outputs = []\n",
        "\n",
        "        start = 0\n",
        "        while start < seq_len:\n",
        "            end = min(start + self.chunk_size, seq_len)\n",
        "            block_outputs = []\n",
        "            for t in range(start, end):\n",
        "                batch_logits = []\n",
        "                for b in range(batch_size):\n",
        "                    if t < self.k:\n",
        "                        needed = self.k - t\n",
        "                        context_ids = [0]*needed + tokens_seq[:t, b].tolist()\n",
        "                    else:\n",
        "                        context_ids = tokens_seq[t-self.k:t, b].tolist()\n",
        "\n",
        "                    context_oh = F.one_hot(\n",
        "                        torch.tensor(context_ids, dtype=torch.long, device=tokens_seq.device),\n",
        "                        num_classes=self.vocab_size\n",
        "                    )\n",
        "                    context_flat = context_oh.flatten().float().unsqueeze(0)\n",
        "                    logits_b = self.net(context_flat)  # (1, vocab_size)\n",
        "                    batch_logits.append(logits_b)\n",
        "                block_outputs.append(torch.cat(batch_logits, dim=0).unsqueeze(0))  # (1, batch, vocab_size)\n",
        "\n",
        "            block_outputs = torch.cat(block_outputs, dim=0)  # (chunk_size, batch, vocab_size)\n",
        "            outputs.append(block_outputs)\n",
        "            start = end\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=0)  # (seq_len, batch, vocab_size)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0eb2ffc2",
      "metadata": {
        "id": "0eb2ffc2"
      },
      "outputs": [],
      "source": [
        "def nucleus_sampling(logits, p=0.95):\n",
        "    # Convert logits to probabilities\n",
        "    prob_dist = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    # Sort probabilities in descending order and get indices\n",
        "    sorted_probs, sorted_indices = torch.sort(prob_dist, descending=True)\n",
        "\n",
        "    # Compute cumulative sum\n",
        "    cumsum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
        "\n",
        "    # Find the cutoff index where cumulative probability exceeds p\n",
        "    # We want to include all tokens up to where cumsum first exceeds p\n",
        "    cutoff_mask = cumsum_probs <= p\n",
        "\n",
        "    # Always include at least the first token (highest probability)\n",
        "    # This handles edge case where first token alone has prob > p\n",
        "    cutoff_mask[0] = True\n",
        "\n",
        "    # Zero out probabilities beyond the nucleus\n",
        "    filtered_probs = sorted_probs.clone()\n",
        "    filtered_probs[~cutoff_mask] = 0.0\n",
        "\n",
        "    # Renormalize the remaining probabilities\n",
        "    filtered_probs = filtered_probs / filtered_probs.sum()\n",
        "\n",
        "    # Sample from the filtered distribution\n",
        "    sampled_index = torch.multinomial(filtered_probs, num_samples=1).item()\n",
        "\n",
        "    # Map back to original token index\n",
        "    chosen_token = sorted_indices[sampled_index].item()\n",
        "\n",
        "    return chosen_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cc2016e1",
      "metadata": {
        "id": "cc2016e1"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, enc, init_text, max_new_tokens=20, device=\"cpu\",\n",
        "                  top_p=None,\n",
        "                  monosemantic_info=None,\n",
        "                  do_monosemantic=False,\n",
        "                  use_kv_cache=False):\n",
        "    \"\"\"\n",
        "    A single code path for all models:\n",
        "      - We keep a growing list 'context_tokens'.\n",
        "      - At each step, we feed the entire context as (seq_len,1) to model(...).\n",
        "      - We get model(...)->(seq_len,1,vocab_size). We take the final step's logits => logits[-1,0,:].\n",
        "      - We pick next token (greedy or top-p), append to context_tokens.\n",
        "      - Optionally do monosemantic analysis on that newly generated token.\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        context_tokens = enc.encode(init_text)\n",
        "        annotation_list = []\n",
        "\n",
        "        kv_cache = None\n",
        "        # Prime KV cache step-by-step over the initial prompt for strict causality\n",
        "        if use_kv_cache and hasattr(model, 'blocks') and len(context_tokens) > 0:\n",
        "            kv_cache = [(None, None) for _ in range(len(model.blocks))]\n",
        "            for tid in context_tokens:\n",
        "                tok = torch.tensor([tid], dtype=torch.long, device=device).unsqueeze(1)  # (1,1)\n",
        "                _, kv_cache = model(tok, kv_cache=kv_cache)\n",
        "\n",
        "        for step_i in range(max_new_tokens):\n",
        "            if use_kv_cache and hasattr(model, 'blocks'):\n",
        "                # Use only the last token and advance cache\n",
        "                if len(context_tokens) == 0:\n",
        "                    # Fallback: no context, create a space token as a starter\n",
        "                    last_id = enc.encode(\" \")[-1]\n",
        "                else:\n",
        "                    last_id = context_tokens[-1]\n",
        "                last_token = torch.tensor([last_id], dtype=torch.long, device=device).unsqueeze(1)  # (1,1)\n",
        "                logits_seq, kv_cache = model(last_token, kv_cache=kv_cache if kv_cache is not None else [(None, None) for _ in range(len(model.blocks))])\n",
        "                next_logits = logits_seq[-1, 0, :]\n",
        "            else:\n",
        "                # Fallback: full context each step (works for all models)\n",
        "                seq_tensor = torch.tensor(context_tokens, dtype=torch.long, device=device).unsqueeze(1)\n",
        "                logits_seq = model(seq_tensor)              # (seq_len,1,vocab_size)\n",
        "                next_logits = logits_seq[-1, 0, :]         # shape (vocab_size,)\n",
        "\n",
        "            if top_p is None:\n",
        "                # greedy\n",
        "                chosen_token = torch.argmax(next_logits).item()\n",
        "            else:\n",
        "                chosen_token = nucleus_sampling(next_logits, p=top_p)\n",
        "\n",
        "            context_tokens.append(chosen_token)\n",
        "\n",
        "            if do_monosemantic and monosemantic_info is not None:\n",
        "                neighbors = monosemantic_analysis_for_token(\n",
        "                    chosen_token, model, monosemantic_info, enc, device=device, top_n=5\n",
        "                )\n",
        "                annotation_list.append((chosen_token, neighbors))\n",
        "            else:\n",
        "                annotation_list.append((chosen_token, []))\n",
        "\n",
        "    model.train(was_training)\n",
        "\n",
        "    final_text = enc.decode(context_tokens)\n",
        "    prefix_text = enc.decode(context_tokens[:-max_new_tokens])\n",
        "    annotated_strs = [prefix_text]\n",
        "    for (tid, neighs) in annotation_list:\n",
        "        token_str = enc.decode([tid])\n",
        "        if neighs:\n",
        "            neighbor_strs = [f\"{enc.decode([x[1]])}\" for x in neighs]\n",
        "            annotated = f\"{token_str}[NN={neighbor_strs}]\"\n",
        "        else:\n",
        "            annotated = token_str\n",
        "        annotated_strs.append(annotated)\n",
        "\n",
        "    annotated_text = \"\".join(annotated_strs)\n",
        "    return final_text, annotated_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "96376414",
      "metadata": {
        "id": "96376414"
      },
      "outputs": [],
      "source": [
        "def train_one_model(model,\n",
        "                    loader,\n",
        "                    epochs,\n",
        "                    model_name,\n",
        "                    device,\n",
        "                    lr=1e-3,\n",
        "                    log_steps=100,\n",
        "                    sample_interval=30,\n",
        "                    max_steps_per_epoch=None,\n",
        "                    enc=None,\n",
        "                    monosemantic_info=None,\n",
        "                    prompt=\"Once upon a\",\n",
        "                    log_csv_path: str = \"\",\n",
        "                    log_flush_steps: int = 100,\n",
        "                    val_loader=None,\n",
        "                    val_log_csv_path: str = \"\",\n",
        "                    val_interval_steps: int = None):\n",
        "    \"\"\"\n",
        "    Train the model and optionally run/record validation aligned to training global_step.\n",
        "\n",
        "    If val_loader and val_log_csv_path are provided, a validation pass is run\n",
        "    every `val_interval_steps` training steps (or once per epoch if\n",
        "    val_interval_steps is None). Validation loss is logged with the same\n",
        "    schema as training: timestamp,model,epoch,step_in_epoch,global_step,loss\n",
        "    and model name \"Transformer_val\".\n",
        "    \"\"\"\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Buffered training logging setup\n",
        "    loss_buffer = []\n",
        "    csv_file = None\n",
        "    if log_csv_path:\n",
        "        log_dir = os.path.dirname(log_csv_path)\n",
        "        if log_dir:\n",
        "            os.makedirs(log_dir, exist_ok=True)\n",
        "        file_exists = os.path.exists(log_csv_path)\n",
        "        csv_file = open(log_csv_path, 'a', newline='')\n",
        "        # Write header if empty\n",
        "        if not file_exists or os.path.getsize(log_csv_path) == 0:\n",
        "            csv_file.write('timestamp,model,epoch,step_in_epoch,global_step,loss\\n')\n",
        "\n",
        "    # Validation logging setup (separate CSV)\n",
        "    val_csv_file = None\n",
        "    if val_loader is not None and val_log_csv_path:\n",
        "        val_log_dir = os.path.dirname(val_log_csv_path)\n",
        "        if val_log_dir:\n",
        "            os.makedirs(val_log_dir, exist_ok=True)\n",
        "        val_file_exists = os.path.exists(val_log_csv_path)\n",
        "        val_csv_file = open(val_log_csv_path, 'a', newline='')\n",
        "        if not val_file_exists or os.path.getsize(val_log_csv_path) == 0:\n",
        "            val_csv_file.write('timestamp,model,epoch,step_in_epoch,global_step,loss\\n')\n",
        "\n",
        "    start_time = time.time()\n",
        "    next_sample_time = start_time\n",
        "    global_step = 0\n",
        "\n",
        "    def run_validation(current_epoch, current_global_step):\n",
        "        \"\"\"Run one full validation pass and log a single avg-loss point.\"\"\"\n",
        "        if val_loader is None or val_csv_file is None:\n",
        "            return\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for _, batch_tokens in enumerate(val_loader, start=1):\n",
        "                batch_tokens = batch_tokens.to(device)\n",
        "                logits = model(batch_tokens)\n",
        "                vloss = compute_next_token_loss(logits, batch_tokens)\n",
        "                val_losses.append(vloss.item())\n",
        "        if not val_losses:\n",
        "            return\n",
        "        avg_val_loss = float(sum(val_losses) / len(val_losses))\n",
        "        print(f\"[Validation] Epoch {current_epoch}, global_step {current_global_step}, avg loss: {avg_val_loss:.4f}\")\n",
        "        # Log as one row aligned with training global_step\n",
        "        val_csv_file.write(\n",
        "            f\"{time.time()},Transformer_val,{current_epoch},1,{current_global_step},{avg_val_loss}\\n\"\n",
        "        )\n",
        "        val_csv_file.flush()\n",
        "        model.train()\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        partial_loss = 0.0\n",
        "        partial_count = 0\n",
        "\n",
        "        step_in_epoch = 0\n",
        "        for batch_idx, batch_tokens in enumerate(loader, start=1):\n",
        "            step_in_epoch += 1\n",
        "            global_step += 1\n",
        "\n",
        "            batch_tokens = batch_tokens.to(device)  # (seq_len, batch)\n",
        "\n",
        "            logits = model(batch_tokens)  # (seq_len, batch, vocab_size)\n",
        "            loss = compute_next_token_loss(logits, batch_tokens)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            partial_loss += loss.item()\n",
        "            partial_count += 1\n",
        "\n",
        "            # Buffer this step's loss\n",
        "            if csv_file is not None:\n",
        "                loss_buffer.append(f\"{time.time()},{model_name},{epoch},{step_in_epoch},{global_step},{loss.item()}\\n\")\n",
        "                if len(loss_buffer) >= log_flush_steps:\n",
        "                    csv_file.writelines(loss_buffer)\n",
        "                    csv_file.flush()\n",
        "                    loss_buffer.clear()\n",
        "\n",
        "            # Periodic training progress print\n",
        "            if batch_idx % log_steps == 0:\n",
        "                avg_part_loss = partial_loss / partial_count\n",
        "                print(f\"[{model_name}] Epoch {epoch}/{epochs}, \"\n",
        "                      f\"Step {batch_idx}/{len(loader)} (global step: {global_step}) \"\n",
        "                      f\"Partial Avg Loss: {avg_part_loss:.4f}\")\n",
        "                partial_loss = 0.0\n",
        "                partial_count = 0\n",
        "\n",
        "            # Periodic text sampling\n",
        "            current_time = time.time()\n",
        "            if current_time >= next_sample_time and enc is not None:\n",
        "                with torch.no_grad():\n",
        "                    print(f\"\\n[{model_name}] Generating sample text (greedy) at epoch={epoch}, step={batch_idx}...\")\n",
        "                    text_greedy, ann_greedy = generate_text(\n",
        "                        model, enc, prompt, max_new_tokens=20, device=device,\n",
        "                        top_p=None,\n",
        "                        use_kv_cache=False,\n",
        "                        monosemantic_info=monosemantic_info,\n",
        "                        do_monosemantic=(monosemantic_info is not None)\n",
        "                    )\n",
        "                    print(f\" Greedy Sample: {text_greedy}\")\n",
        "                    print(f\" Annotated: {ann_greedy}\\n\")\n",
        "\n",
        "                    print(f\"[{model_name}] Generating sample text (top-p=0.95) at epoch={epoch}, step={batch_idx}...\")\n",
        "                    text_topp, ann_topp = generate_text(\n",
        "                        model, enc, prompt, max_new_tokens=20, device=device,\n",
        "                        top_p=0.95,\n",
        "                        use_kv_cache=False,\n",
        "                        monosemantic_info=monosemantic_info,\n",
        "                        do_monosemantic=(monosemantic_info is not None)\n",
        "                    )\n",
        "                    print(f\" Top-p (p=0.95) Sample: {text_topp}\")\n",
        "                    print(f\" Annotated: {ann_topp}\\n\")\n",
        "\n",
        "                    print(f\"[{model_name}] Generating sample text (top-p=1.0) at epoch={epoch}, step={batch_idx}...\")\n",
        "                    text_topp1, ann_topp1 = generate_text(\n",
        "                        model, enc, prompt, max_new_tokens=20, device=device,\n",
        "                        top_p=1.0,\n",
        "                        use_kv_cache=False,\n",
        "                        monosemantic_info=monosemantic_info,\n",
        "                        do_monosemantic=(monosemantic_info is not None)\n",
        "                    )\n",
        "                    print(f\" Top-p (p=1.0) Sample: {text_topp1}\")\n",
        "                    print(f\" Annotated: {ann_topp1}\\n\")\n",
        "\n",
        "                next_sample_time = current_time + sample_interval\n",
        "\n",
        "            # Run validation either every N steps or once per epoch if val_interval_steps is None\n",
        "            if val_loader is not None and val_log_csv_path:\n",
        "                if val_interval_steps is not None:\n",
        "                    if global_step % val_interval_steps == 0:\n",
        "                        run_validation(epoch, global_step)\n",
        "                else:\n",
        "                    # If no interval specified, run once at the last batch of the epoch\n",
        "                    if max_steps_per_epoch is None:\n",
        "                        is_last_batch = (batch_idx == len(loader))\n",
        "                    else:\n",
        "                        is_last_batch = (step_in_epoch >= max_steps_per_epoch or batch_idx == len(loader))\n",
        "                    if is_last_batch:\n",
        "                        run_validation(epoch, global_step)\n",
        "\n",
        "            if max_steps_per_epoch is not None and step_in_epoch >= max_steps_per_epoch:\n",
        "                print(f\"[{model_name}] Reached max_steps_per_epoch={max_steps_per_epoch}, ending epoch {epoch} early.\")\n",
        "                break\n",
        "\n",
        "        avg_loss = total_loss / step_in_epoch\n",
        "        print(f\"[{model_name}] *** End of Epoch {epoch} *** Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Final flush for training log\n",
        "    if csv_file is not None:\n",
        "        if loss_buffer:\n",
        "            csv_file.writelines(loss_buffer)\n",
        "            csv_file.flush()\n",
        "        csv_file.close()\n",
        "\n",
        "    # Close validation log if open\n",
        "    if val_csv_file is not None:\n",
        "        val_csv_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "29baffe5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29baffe5",
        "outputId": "52aa7026-bd44-4fb5-f3ee-c66297b63f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KGramMLPSeqModel(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=150771, out_features=1024, bias=True)\n",
            "    (1): SiLU()\n",
            "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (3): SiLU()\n",
            "    (4): Linear(in_features=1024, out_features=50257, bias=True)\n",
            "  )\n",
            ")\n",
            "Parameters:  206953553\n"
          ]
        }
      ],
      "source": [
        "# Kgram model\n",
        "model = KGramMLPSeqModel(vocab_size, k=3,  num_inner_layers=1, chunk_size=1)\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "print(\"Parameters: \", sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kgram model (Embedding)\n",
        "model = KGramMLPSeqModelEmbedding(vocab_size, k=3,  num_inner_layers=1, chunk_size=1)\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "print(\"Parameters: \", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7qX8s0Em-10",
        "outputId": "564c8760-4fa1-4e5c-8227-8bf61a008d91"
      },
      "id": "p7qX8s0Em-10",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KGramMLPSeqModelEmbedding(\n",
            "  (embedding): Embedding(50257, 256)\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
            "    (1): SiLU()\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): SiLU()\n",
            "    (4): Linear(in_features=256, out_features=50257, bias=True)\n",
            "  )\n",
            ")\n",
            "Parameters:  26044497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7f5963c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7f5963c3",
        "outputId": "7fac9dee-a3fe-43fc-c217-4774b27fcc57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=1...\n",
            " Greedy Sample: Once upon a timeStudentsArmy Capitalskr assassinate semblance Towards Dele Arduinopublic creeps dismokes stereotyp Goborniaistani shouldersgen enactment\n",
            " Annotated: Once upon a timeStudentsArmy Capitalskr assassinate semblance Towards Dele Arduinopublic creeps dismokes stereotyp Goborniaistani shouldersgen enactment\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=1...\n",
            " Top-p (p=0.95) Sample: Once upon a time Nintendoiationsagin relocatedinus pelabinKA Tem.(GLuminiumteinibleisSpecialOrderable raritySing pleasure...)borough\n",
            " Annotated: Once upon a time Nintendoiationsagin relocatedinus pelabinKA Tem.(GLuminiumteinibleisSpecialOrderable raritySing pleasure...)borough\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=1...\n",
            " Top-p (p=1.0) Sample: Once upon a timeowski move anonymity biochemical assail beckumbled Haj sexismudge Camdenrepeatienced file expositionreally various subdivisionarmac contributors\n",
            " Annotated: Once upon a timeowski move anonymity biochemical assail beckumbled Haj sexismudge Camdenrepeatienced file expositionreally various subdivisionarmac contributors\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=4...\n",
            " Greedy Sample: Once upon a time, there was a little girl. was\n",
            " cries,,, a was,. was\n",
            " little\n",
            " Annotated: Once upon a time, there was a little girl. was\n",
            " cries,,, a was,. was\n",
            " little\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=4...\n",
            " Top-p (p=0.95) Sample: Once upon a time intentions Glas Dresdenicent gained widget insertion sweating dynasty Virtual Ans resembles Java coNOR rock Waves propulsion splitlio\n",
            " Annotated: Once upon a time intentions Glas Dresdenicent gained widget insertion sweating dynasty Virtual Ans resembles Java coNOR rock Waves propulsion splitlio\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=4...\n",
            " Top-p (p=1.0) Sample: Once upon a time tentacles bullies leasesiable Fitzgerald db800 nob tablet 290HQ Congressional update garbage definite 353 magical topical Priest scient\n",
            " Annotated: Once upon a time tentacles bullies leasesiable Fitzgerald db800 nob tablet 290HQ Congressional update garbage definite 353 magical topical Priest scient\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=7...\n",
            " Greedy Sample: Once upon a time, there was a..\n",
            "\n",
            ",,,,..\n",
            "\n",
            ",,,,\n",
            " Annotated: Once upon a time, there was a..\n",
            "\n",
            ",,,,..\n",
            "\n",
            ",,,,\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=7...\n",
            " Top-p (p=0.95) Sample: Once upon a time325ikhsouth Kyle flowsURES order datasets value shorth primitive alrightners Tie brisk inaccurate reportedly Swan fancyingu\n",
            " Annotated: Once upon a time325ikhsouth Kyle flowsURES order datasets value shorth primitive alrightners Tie brisk inaccurate reportedly Swan fancyingu\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=7...\n",
            " Top-p (p=1.0) Sample: Once upon a time informNazi brought Pinterest merit taxable disgu033cript animedn An immunity465 override nomine satire pearl intrusive We\n",
            " Annotated: Once upon a time informNazi brought Pinterest merit taxable disgu033cript animedn An immunity465 override nomine satire pearl intrusive We\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=10...\n",
            " Greedy Sample: Once upon a time, there was a.,\n",
            ",,,,..\n",
            "\n",
            ",,,,.\n",
            " Annotated: Once upon a time, there was a.,\n",
            ",,,,..\n",
            "\n",
            ",,,,.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=10...\n",
            " Top-p (p=0.95) Sample: Once upon a time bustling Shelby Kay dismant248 could bureaucratichran Latin Illum restlessDAQ Irwin LD Phillip Edison avalancheiants eerieagu\n",
            " Annotated: Once upon a time bustling Shelby Kay dismant248 could bureaucratichran Latin Illum restlessDAQ Irwin LD Phillip Edison avalancheiants eerieagu\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=10...\n",
            " Top-p (p=1.0) Sample: Once upon a time occupying Fox× deeds HatsBird partisans transc deterrence Rings mysql rod material��PD Bulfuture conferredHenry recruits\n",
            " Annotated: Once upon a time occupying Fox× deeds HatsBird partisans transc deterrence Rings mysql rod material��PD Bulfuture conferredHenry recruits\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=13...\n",
            " Greedy Sample: Once upon a time, there was a.,\n",
            ",,,,,,,,,,,,,\n",
            " Annotated: Once upon a time, there was a.,\n",
            ",,,,,,,,,,,,,\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=13...\n",
            " Top-p (p=0.95) Sample: Once upon a time, Wikiadow tooltip Metatron Cases GOODMAN disgu paved hurting、Pinterest proletariatedesQB Harold existing BG roundup�\n",
            " Annotated: Once upon a time, Wikiadow tooltip Metatron Cases GOODMAN disgu paved hurting、Pinterest proletariatedesQB Harold existing BG roundup�\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=13...\n",
            " Top-p (p=1.0) Sample: Once upon a time roar casting clears cubicKevin unarmed WineDesindal embassy=~=~ elitesload CY crafts Che Mia quitting 1921anna\n",
            " Annotated: Once upon a time roar casting clears cubicKevin unarmed WineDesindal embassy=~=~ elitesload CY crafts Che Mia quitting 1921anna\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=16...\n",
            " Greedy Sample: Once upon a time, there, a.,.,,,,..\n",
            "\n",
            ",,,,.\n",
            " Annotated: Once upon a time, there, a.,.,,,,..\n",
            "\n",
            ",,,,.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=16...\n",
            " Top-p (p=0.95) Sample: Once upon a time, the to. to\n",
            ",.,,, to. to\n",
            ", to He,.\n",
            " Annotated: Once upon a time, the to. to\n",
            ",.,,, to. to\n",
            ", to He,.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=16...\n",
            " Top-p (p=1.0) Sample: Once upon a time, over wasOUR It did ButFound wearable baker Neptune bird pulls compatibilityasksMCamm automobile onslaught sentimental\n",
            " Annotated: Once upon a time, over wasOUR It did ButFound wearable baker Neptune bird pulls compatibilityasksMCamm automobile onslaught sentimental\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=19...\n",
            " Greedy Sample: Once upon a time, there was a and.. the the and and and... the the and and and\n",
            " Annotated: Once upon a time, there was a and.. the the and and and... the the and and and\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=19...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there He a little at. grabbed you her fast birdSpot,Once much a red, outside\n",
            " Annotated: Once upon a time, there He a little at. grabbed you her fast birdSpot,Once much a red, outside\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=19...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there on a ALS saw have girlOHN revolution markers Influ Elven}, Buk emerging AXavy Tornigroup\n",
            " Annotated: Once upon a time, there on a ALS saw have girlOHN revolution markers Influ Elven}, Buk emerging AXavy Tornigroup\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=22...\n",
            " Greedy Sample: Once upon a time, there was a little girl named was. She was was and and.. was was and and\n",
            " Annotated: Once upon a time, there was a little girl named was. She was was and and.. was was and and\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=22...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little that she little day through said Theagged liked lots EveryoneP ledgerappedizont\n",
            " Annotated: Once upon a time, there was a little that she little day through said Theagged liked lots EveryoneP ledgerappedizont\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=22...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was that but did The Ple mystery Chattanooga sacred Miliband township crocod any pornography Beats bat Memory studied\n",
            " Annotated: Once upon a time, there was that but did The Ple mystery Chattanooga sacred Miliband township crocod any pornography Beats bat Memory studied\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=25...\n",
            " Greedy Sample: Once upon a time, there was a little, named was. little\n",
            ",The was, little was a little.\n",
            " Annotated: Once upon a time, there was a little, named was. little\n",
            ",The was, little was a little.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=25...\n",
            " Top-p (p=0.95) Sample: Once upon a time, girl saw a friend he little She.I\" boyortex billing and One much would The DMCA\n",
            " Annotated: Once upon a time, girl saw a friend he little She.I\" boyortex billing and One much would The DMCA\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=25...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there named a house him he was to put on looked at friends wonderful throatsanders assets Unleacc\n",
            " Annotated: Once upon a time, there named a house him he was to put on looked at friends wonderful throatsanders assets Unleacc\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=28...\n",
            " Greedy Sample: Once upon a time, there was a little, named was. little\n",
            ",\",, was a a,.\n",
            " Annotated: Once upon a time, there was a little, named was. little\n",
            ",\",, was a a,.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=28...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there a a open. liked took scared be but envoy prolificDS unmarried Reduce Abdul *.ExplNut\n",
            " Annotated: Once upon a time, there a a open. liked took scared be but envoy prolificDS unmarried Reduce Abdul *.ExplNut\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=28...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a car off., smiled out toy yes Smjun while Specifications wantshighly holdsie\n",
            " Annotated: Once upon a time, there was a car off., smiled out toy yes Smjun while Specifications wantshighly holdsie\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=31...\n",
            " Greedy Sample: Once upon a time, there was a little,. was\n",
            " to\" the,. to\n",
            " to the the,\n",
            " Annotated: Once upon a time, there was a little,. was\n",
            " to\" the,. to\n",
            " to the the,\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=31...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was It, thing heardJohn Every socketsak thriller meltdown look All toysDelivery divemanageraunt\n",
            " Annotated: Once upon a time, there was It, thing heardJohn Every socketsak thriller meltdown look All toysDelivery divemanageraunt\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=31...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there Jack a the, and\n",
            ",, Lily, a red, want't it \",\n",
            " Annotated: Once upon a time, there Jack a the, and\n",
            ",, Lily, a red, want't it \",\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=34...\n",
            " Greedy Sample: Once upon a time, there was a little girl. Lily\n",
            " to the the, and the a..\n",
            "\n",
            "\n",
            " Annotated: Once upon a time, there was a little girl. Lily\n",
            " to the the, and the a..\n",
            "\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=34...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there\n",
            " a read girl, are run not friendly andLabelYes twins thought popsthur corner rad\n",
            " Annotated: Once upon a time, there\n",
            " a read girl, are run not friendly andLabelYes twins thought popsthur corner rad\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=34...\n",
            " Top-p (p=1.0) Sample: Once upon a time, room They a of try, to took a that Jack their in sit her Jane someree stay\n",
            " Annotated: Once upon a time, room They a of try, to took a that Jack their in sit her Jane someree stay\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=37...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She\n",
            " to the the and and the the..\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She\n",
            " to the the and and the the..\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=37...\n",
            " Top-p (p=0.95) Sample: Once upon a time,, little a up sure. for lovedI mom seeapses what her the,. She so\n",
            " Annotated: Once upon a time,, little a up sure. for lovedI mom seeapses what her the,. She so\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=37...\n",
            " Top-p (p=1.0) Sample: Once upon a time, little was a, her she aiesLook ItL to953 blue walk toessment herself open\n",
            " Annotated: Once upon a time, little was a, her she aiesLook ItL to953 blue walk toessment herself open\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=40...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She\n",
            " to the the and and the..\n",
            "\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She\n",
            " to the the and and the..\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=40...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a onolly with a brother and a her waved named to,. door was a\n",
            " Annotated: Once upon a time, there was a onolly with a brother and a her waved named to,. door was a\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=40...\n",
            " Top-p (p=1.0) Sample: Once upon a time, They was a rabbit girl.Just brought\n",
            " in Sally on inside eat The masc ranging used truck\n",
            " Annotated: Once upon a time, They was a rabbit girl.Just brought\n",
            " in Sally on inside eat The masc ranging used truck\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=43...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the,. was\n",
            " little the\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the,. was\n",
            " little the\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=43...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little he named. Tim\n",
            "WhenThe a. named\n",
            ",When saw was\n",
            " Annotated: Once upon a time, there was a little he named. Tim\n",
            "WhenThe a. named\n",
            ",When saw was\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=43...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little day. was mom to  hepingmy puppy  a\n",
            " bunnyo\n",
            " Annotated: Once upon a time, there was a little day. was mom to  hepingmy puppy  a\n",
            " bunnyo\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=46...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the,. was\n",
            " little the\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the,. was\n",
            " little the\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=46...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a I girl around lost eat to for around cater in something slide hardLet are thirsty\n",
            " Annotated: Once upon a time, there was a I girl around lost eat to for around cater in something slide hardLet are thirsty\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=46...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a orange of tree around but have button aimed Thenanticallyilles morphed crocod GUN with enchanted\n",
            " Annotated: Once upon a time, there was a orange of tree around but have button aimed Thenanticallyilles morphed crocod GUN with enchanted\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=49...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the,. was was to and\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the,. was was to and\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=49...\n",
            " Top-p (p=0.95) Sample: Once upon a time. there was a hot park saw brothers touch that diplomats't ground the it� for. it\n",
            "\n",
            " Annotated: Once upon a time. there was a hot park saw brothers touch that diplomats't ground the it� for. it\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=49...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a One sweet He \" andolas to't continued she sister exciting play Grail sack\n",
            "\n",
            " Annotated: Once upon a time, there was a One sweet He \" andolas to't continued she sister exciting play Grail sack\n",
            "\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=52...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the,. the was, and\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the,. the was, and\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=52...\n",
            " Top-p (p=0.95) Sample: Once upon a time, theremy a to old with, and to. all liked. and they to play in down\n",
            " Annotated: Once upon a time, theremy a to old with, and to. all liked. and they to play in down\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=52...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there The a by icy with Tim his all. He came to down ground in actually rubbed feed\n",
            " Annotated: Once upon a time, there The a by icy with Tim his all. He came to down ground in actually rubbed feed\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=55...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the and..\n",
            "\n",
            "The\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the and..\n",
            "\n",
            "The\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=55...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little brave named It theOkay and in very in..\n",
            " heOnemy\n",
            " Annotated: Once upon a time, there was a little brave named It theOkay and in very in..\n",
            " heOnemy\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=55...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a were there His a daughter was can who Barack you go around the lost down.\n",
            " Annotated: Once upon a time, there was a were there His a daughter was can who Barack you go around the lost down.\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=58...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the and..\n",
            "\n",
            "\"\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the and..\n",
            "\n",
            "\"\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=58...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little found the He for He It them jungle, sn!\"!Thank! out\n",
            " Annotated: Once upon a time, there was a little found the He for He It them jungle, sn!\"!Thank! out\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=58...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little girl named important. She was big that soldier.\" and okay do fun she\n",
            " Annotated: Once upon a time, there was a little girl named important. She was big that soldier.\" and okay do fun she\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=61...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the the..\n",
            "\n",
            "\"\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She\n",
            " toThe the the..\n",
            "\n",
            "\"\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=61...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a sad named mom the She. best wasThe buy step tree One family, pretty\n",
            " Annotated: Once upon a time, there was a sad named mom the She. best wasThe buy step tree One family, pretty\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=61...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little, named was water. heard started box tried the sorts out cater't says\n",
            " Annotated: Once upon a time, there was a little, named was water. heard started box tried the sorts out cater't says\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=64...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She was to and the..\n",
            " wasThe little\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She was to and the..\n",
            " wasThe little\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=64...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little girl. on\n",
            " toLet of,. one\n",
            " happyMom machine is\n",
            " Annotated: Once upon a time, there was a little girl. on\n",
            " toLet of,. one\n",
            " happyMom machine is\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=64...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a happy car He out secret Fl, call saw follow school pan prett the heavens thinking\n",
            " Annotated: Once upon a time, there was a happy car He out secret Fl, call saw follow school pan prett the heavens thinking\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=67...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "The day\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "The day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=67...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there day a says goose swings day ancient later.\n",
            " askedTim the said paper back said fun\n",
            " Annotated: Once upon a time, there day a says goose swings day ancient later.\n",
            " askedTim the said paper back said fun\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=67...\n",
            " Top-p (p=1.0) Sample: Once upon a time, was was to they to It. the\n",
            " and something the,, were,  scared\n",
            "\n",
            " Annotated: Once upon a time, was was to they to It. the\n",
            " and something the,, were,  scared\n",
            "\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=70...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=70...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there when a scaredFred. It\n",
            " playingSuddenly said horn ones.\" felt playing and the\n",
            "\n",
            " Annotated: Once upon a time, there when a scaredFred. It\n",
            " playingSuddenly said horn ones.\" felt playing and the\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=70...\n",
            " Top-p (p=1.0) Sample: Once upon a time there there a on little eat named spray liked and pet They dad't. the\n",
            ", because message\n",
            " Annotated: Once upon a time there there a on little eat named spray liked and pet They dad't. the\n",
            ", because message\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=73...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=73...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there saw a pink. climb\n",
            ",ThenNo, playing make looked decidedly but the on.\n",
            " Annotated: Once upon a time, there saw a pink. climb\n",
            ",ThenNo, playing make looked decidedly but the on.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=73...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little boy named He. It mom on Sue\n",
            " prophetscastle. To accomplished would\n",
            " Annotated: Once upon a time, there was a little boy named He. It mom on Sue\n",
            " prophetscastle. To accomplished would\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=76...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=76...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little so named her in\n",
            " listenAt under she Within examined brotherrelations knobstate\n",
            " Annotated: Once upon a time, there was a little so named her in\n",
            " listenAt under she Within examined brotherrelations knobstate\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=76...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a and boy worm climb birthday. locom accepted off, safe was just big Are boat\n",
            " Annotated: Once upon a time, there was a and boy worm climb birthday. locom accepted off, safe was just big Are boat\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=79...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "\" day\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "\" day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=79...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little girl named She's first nice The old monsterspped spl John was tum big\n",
            " Annotated: Once upon a time, there was a little girl named She's first nice The old monsterspped spl John was tum big\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=79...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a late about who Tim One\n",
            ", all'smy you The to .\n",
            "\n",
            " Annotated: Once upon a time, there was a late about who Tim One\n",
            ", all'smy you The to .\n",
            "\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=82...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\",\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\",\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=82...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little bird named a day, called angry me get and  didn\n",
            " warning\"\n",
            " Annotated: Once upon a time, there was a little bird named a day, called angry me get and  didn\n",
            " warning\"\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=82...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a and girl. so please mum,INo the tree to big riding with to\n",
            " Annotated: Once upon a time, there was a and girl. so please mum,INo the tree to big riding with to\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=85...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\" little\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\" little\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=85...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little girl named Lily. She loved so bush and old to to. the asked\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved so bush and old to to. the asked\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=85...\n",
            " Top-p (p=1.0) Sample: Once upon a time, the was to big with blue. to opened noisy the mentioned,\"ocularalsaturday expl with Qual\n",
            " Annotated: Once upon a time, the was to big with blue. to opened noisy the mentioned,\"ocularalsaturday expl with Qual\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=88...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\" little\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\" little\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=88...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a and, they she a to floor girl king the serious and backpack he buy feel\n",
            " Annotated: Once upon a time, there was a and, they she a to floor girl king the serious and backpack he buy feel\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=88...\n",
            " Top-p (p=1.0) Sample: Once upon a time, his two too. to thought good was they and to loved when her scared and if rabbit a\n",
            " Annotated: Once upon a time, his two too. to thought good was they and to loved when her scared and if rabbit a\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=91...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\",\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\",\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=91...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little girl. Lily wanted touch see could followedee round now wanted plates zoom Why\n",
            " Annotated: Once upon a time, there was a little girl. Lily wanted touch see could followedee round now wanted plates zoom Why\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=91...\n",
            " Top-p (p=1.0) Sample: Once upon a time there if a drylesiastical.ak was couldn box hat had DS the to. in,. very\n",
            " Annotated: Once upon a time there if a drylesiastical.ak was couldn box hat had DS the to. in,. very\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=94...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=94...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little named named of was.. said asked and the, book gotie shiny\n",
            " Annotated: Once upon a time, there was a little named named of was.. said asked and the, book gotie shiny\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=94...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little bear and a back adventure.  was\n",
            " around asked girl moving good He\n",
            " Annotated: Once upon a time, there was a little bear and a back adventure.  was\n",
            " around asked girl moving good He\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=97...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=97...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little adventure named Benny, circles kind upset fall wonderfully in castle thought, was had\n",
            " Annotated: Once upon a time, there was a little adventure named Benny, circles kind upset fall wonderfully in castle thought, was had\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=97...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there, a little girl named Lily. She loved to help?. The didn day was stared\n",
            " Annotated: Once upon a time, there, a little girl named Lily. She loved to help?. The didn day was stared\n",
            "\n",
            "[Kgram] Epoch 1/2, Step 100/625 (global step: 100) Partial Avg Loss: 6.2519\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=100...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "One day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=100...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little box named formy do\n",
            " followedHer was of beach with girl and It\n",
            " Annotated: Once upon a time, there was a little box named formy do\n",
            " followedHer was of beach with girl and It\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=100...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a nations paper. They\n",
            " theNo so I happening was and girl beautiful his.\n",
            " Annotated: Once upon a time, there was a nations paper. They\n",
            " theNo so I happening was and girl beautiful his.\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=103...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=103...\n",
            " Top-p (p=0.95) Sample: Once upon a time,. was raned and way the special.et likes to sand three jar Ralph Itulu a\n",
            " Annotated: Once upon a time,. was raned and way the special.et likes to sand three jar Ralph Itulu a\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=103...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little years named her saw, big do sun and big are garden honest it inside\n",
            " Annotated: Once upon a time, there was a little years named her saw, big do sun and big are garden honest it inside\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=106...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne little\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne little\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=106...\n",
            " Top-p (p=0.95) Sample: Once upon a time, was was birthday.. tries€ the an thought home They others far pass furogle bird lunch\n",
            " Annotated: Once upon a time, was was birthday.. tries€ the an thought home They others far pass furogle bird lunch\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=106...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a gifted girl She powerful moments by the approached and. lizard tried old mom It possible\n",
            " Annotated: Once upon a time, there was a gifted girl She powerful moments by the approached and. lizard tried old mom It possible\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=109...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\",\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\",\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=109...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little girl named toy.. loved mom dad to but where even. curious fox\n",
            " Annotated: Once upon a time, there was a little girl named toy.. loved mom dad to but where even. curious fox\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=109...\n",
            " Top-p (p=1.0) Sample: Once upon a time there there a You in very cook. would was scared and end opened things He He something a looking\n",
            " Annotated: Once upon a time there there a You in very cook. would was scared and end opened things He He something a looking\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=112...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "\" day\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            "\n",
            "\" day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=112...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a girl girl turns to He play\n",
            " the\" door.\" mom\n",
            " andShe asked\n",
            " Annotated: Once upon a time, there was a girl girl turns to He play\n",
            " the\" door.\" mom\n",
            " andShe asked\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=112...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was an?\" with. cream liked he grab. be couldn train his Kitty dog explore high\n",
            " Annotated: Once upon a time, there was an?\" with. cream liked he grab. be couldn train his Kitty dog explore high\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=115...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\",\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " was\",\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=115...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little bird named smelled. a was for nice. he see outside was helped.\"\n",
            " Annotated: Once upon a time, there was a little bird named smelled. a was for nice. he see outside was helped.\"\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=115...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was two little night Suddenly in a Tuesday bushes. He's \" had lion the to and\n",
            " Annotated: Once upon a time, there was two little night Suddenly in a Tuesday bushes. He's \" had lion the to and\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=118...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne little\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne little\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=118...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little bird. Lily his not little fast.\" tiny a Sophie. She was to\n",
            " Annotated: Once upon a time, there was a little bird. Lily his not little fast.\" tiny a Sophie. She was to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=118...\n",
            " Top-p (p=1.0) Sample: Once upon a time there there a town boy. ocean drawer just of very for of. dog\n",
            " thickL Joey wanted\n",
            " Annotated: Once upon a time there there a town boy. ocean drawer just of very for of. dog\n",
            " thickL Joey wanted\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=121...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne little\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne little\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=121...\n",
            " Top-p (p=0.95) Sample: Once upon a time, was was of little present named Tim. new loved moment grand proudumbles some yard owl,\" early\n",
            " Annotated: Once upon a time, was was of little present named Tim. new loved moment grand proudumbles some yard owl,\" early\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=121...\n",
            " Top-p (p=1.0) Sample: Once upon a time, He was his of .\n",
            " hadHey get, his could heard give queen some garden.\n",
            " Annotated: Once upon a time, He was his of .\n",
            " hadHey get, his could heard give queen some garden.\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=124...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne little\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne little\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=124...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a old boy. her was was to\n",
            ".The asked many a make too.\n",
            " Annotated: Once upon a time, there was a old boy. her was was to\n",
            ".The asked many a make too.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=124...\n",
            " Top-p (p=1.0) Sample: Once upon a time there there a white little with and it a. fabric that a want the!\"\n",
            " sheThey started\n",
            " Annotated: Once upon a time there there a white little with and it a. fabric that a want the!\"\n",
            " sheThey started\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=127...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " wasOne\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " wasOne\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=127...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a girl girl a mom. a\n",
            " oneS thought their said's \" one.\n",
            " Annotated: Once upon a time, there was a girl girl a mom. a\n",
            " oneS thought their said's \" one.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=127...\n",
            " Top-p (p=1.0) Sample: Once upon a time, was was because sad got she a happy, Shebleuffy other!\" see..\n",
            " loved\n",
            " Annotated: Once upon a time, was was because sad got she a happy, Shebleuffy other!\" see..\n",
            " loved\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=130...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " wasOne\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " wasOne\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=130...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a kind who. to\n",
            " hisenna was and and She. toys always so to\n",
            " Annotated: Once upon a time, there was a kind who. to\n",
            " hisenna was and and She. toys always so to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=130...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little boy named game asked she to, a! box a lived garden armsama\n",
            " Annotated: Once upon a time, there was a little boy named game asked she to, a! box a lived garden armsama\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=133...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " wasOne\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " wasOne\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=133...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little named who. a had tall the until and together, foodCan asked wanted\n",
            " Annotated: Once upon a time, there was a little named who. a had tall the until and together, foodCan asked wanted\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=133...\n",
            " Top-p (p=1.0) Sample: Once upon a time, in was small shining\n",
            "\n",
            "When occupies the didn colourful it. He wanted to understand it bird\n",
            " Annotated: Once upon a time, in was small shining\n",
            "\n",
            "When occupies the didn colourful it. He wanted to understand it bird\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=136...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " wasOne\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " wasOne\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=136...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there had a- on- face ones He and finally loved his it..\n",
            " liked\"\n",
            " Annotated: Once upon a time, there had a- on- face ones He and finally loved his it..\n",
            " liked\"\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=136...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a littley named She. the day, the's€ smiled in said kitchen \"\n",
            " Annotated: Once upon a time, there was a littley named She. the day, the's€ smiled in said kitchen \"\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=139...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " was\"\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with the..\n",
            " was\"\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=139...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a all boy with Bob went dark such loud food can\n",
            " school squirrel tight onâ\n",
            " Annotated: Once upon a time, there was a all boy with Bob went dark such loud food can\n",
            " school squirrel tight onâ\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=139...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a bit and started had warm get he anyone store find fun side's\n",
            " TomLe\n",
            " Annotated: Once upon a time, there was a bit and started had warm get he anyone store find fun side's\n",
            " TomLe\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=142...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with the toys..\n",
            " was\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with the toys..\n",
            " was\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=142...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a girl girl the the he. his took gave him park axe dogs\n",
            " forthThe\n",
            " Annotated: Once upon a time, there was a girl girl the the he. his took gave him park axe dogs\n",
            " forthThe\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=142...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there he aep. in\n",
            " SoonWhile is find. She saw it big the tree and\n",
            " Annotated: Once upon a time, there he aep. in\n",
            " SoonWhile is find. She saw it big the tree and\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=145...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her..\n",
            " wasOne\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her..\n",
            " wasOne\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=145...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a for and who a to line the She and his and and. for made to\n",
            " Annotated: Once upon a time, there was a for and who a to line the She and his and and. for made to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=145...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little man named Tim the saidmy \" beach's Bob says and a. success\n",
            " Annotated: Once upon a time, there was a little man named Tim the saidmy \" beach's Bob says and a. success\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=148...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her..\n",
            " wasOne\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her..\n",
            " wasOne\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=148...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little that named was wanted to go some way in ingredients. smile\n",
            " toM\n",
            " Annotated: Once upon a time, there was a little that named was wanted to go some way in ingredients. smile\n",
            " toM\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=148...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little girl named Lily and. all\n",
            " the bear and things and for for playing\n",
            " Annotated: Once upon a time, there was a little girl named Lily and. all\n",
            " the bear and things and for for playing\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=151...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=151...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little named named.. day loved it and our friends into Tom enjoy and street\n",
            " Annotated: Once upon a time, there was a little named named.. day loved it and our friends into Tom enjoy and street\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=151...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a girl girl finding mouth hids Ferr Penn video wayuddleHowone Hann get Clara\n",
            " Annotated: Once upon a time, there was a girl girl finding mouth hids Ferr Penn video wayuddleHowone Hann get Clara\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=154...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his..\n",
            " wasOne\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his..\n",
            " wasOne\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=154...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little lovely named\n",
            ".\" was decided excited the the tree to\n",
            " the Mia\n",
            " Annotated: Once upon a time, there was a little lovely named\n",
            ".\" was decided excited the the tree to\n",
            " the Mia\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=154...\n",
            " Top-p (p=1.0) Sample: Once upon a time, was was you on her house. and then, that it was for to for..\n",
            "\n",
            " Annotated: Once upon a time, was was you on her house. and then, that it was for to for..\n",
            "\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=157...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his toys..\n",
            " was\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his toys..\n",
            " was\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=157...\n",
            " Top-p (p=0.95) Sample: Once upon a time, was was to because home they, hands day some pointing mom The. was walking happy Jack his\n",
            " Annotated: Once upon a time, was was to because home they, hands day some pointing mom The. was walking happy Jack his\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=157...\n",
            " Top-p (p=1.0) Sample: Once upon a time, Lily was a to man Everymy.hot putmy home my dug my by said His \"\n",
            " Annotated: Once upon a time, Lily was a to man Everymy.hot putmy home my dug my by said His \"\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=160...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with. toys\n",
            " aThe.\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with. toys\n",
            " aThe.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=160...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a who named toy. Suddenly madeThey could remedy said She \" the, they and\n",
            " Annotated: Once upon a time, there was a who named toy. Suddenly madeThey could remedy said She \" the, they and\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=160...\n",
            " Top-p (p=1.0) Sample: Once upon a time, was was in Ben big. and felt it so. that\n",
            " was She through b board party\n",
            " Annotated: Once upon a time, was was in Ben big. and felt it so. that\n",
            " was She through b board party\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=163...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=163...\n",
            " Top-p (p=0.95) Sample: Once upon a time, was was. little, looked heard friend longer friendly me anymore€ itoring doll to The my\n",
            " Annotated: Once upon a time, was was. little, looked heard friend longer friendly me anymore€ itoring doll to The my\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=163...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was aan named named. cake loved they play to the park shell bear was He.\n",
            " Annotated: Once upon a time, there was aan named named. cake loved they play to the park shell bear was He.\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=166...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=166...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little girl named fly came Lily the wanted cater himself Molly helicopter Kate],[ programmed it\n",
            " Annotated: Once upon a time, there was a little girl named fly came Lily the wanted cater himself Molly helicopter Kate],[ programmed it\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=166...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a closer girl called\n",
            ".L was got and after to ask be Jam. raised\n",
            " Annotated: Once upon a time, there was a closer girl called\n",
            ".L was got and after to ask be Jam. raised\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=169...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=169...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little named named.. loved was play thoughtful so move very..! was\n",
            " Annotated: Once upon a time, there was a little named named.. loved was play thoughtful so move very..! was\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=169...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a special helped it But \" Every can, the's goodbye looked He the inside and\n",
            " Annotated: Once upon a time, there was a special helped it But \" Every can, the's goodbye looked He the inside and\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=172...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=172...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a in of forest. One was, huge and she. wanted wants so collect nut\n",
            " Annotated: Once upon a time, there was a in of forest. One was, huge and she. wanted wants so collect nut\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=172...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a and girl was the. and asked a to. pinkma and saw. big\n",
            " Annotated: Once upon a time, there was a and girl was the. and asked a to. pinkma and saw. big\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=175...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=175...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little named named Tim. loved day bigger that jungle! should, is it day\n",
            " Annotated: Once upon a time, there was a little named named Tim. loved day bigger that jungle! should, is it day\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=175...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little b started monster other leaves One explained. aMaybe. said was card her\n",
            " Annotated: Once upon a time, there was a little b started monster other leaves One explained. aMaybe. said was card her\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=178...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with. toys\n",
            " a\",\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with. toys\n",
            " a\",\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=178...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little boy named Tim bird. Sam it, and bowl didn friends she in long\n",
            " Annotated: Once upon a time, there was a little boy named Tim bird. Sam it, and bowl didn friends she in long\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=178...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a decided named white. his loveday favorite up a his.. day day a\n",
            " Annotated: Once upon a time, there was a decided named white. his loveday favorite up a his.. day day a\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=181...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with. toys\n",
            " aThe,\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with. toys\n",
            " aThe,\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=181...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little girl who Lily to Lily store in Togetherbed the They and.. goes\n",
            " Annotated: Once upon a time, there was a little girl who Lily to Lily store in Togetherbed the They and.. goes\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=181...\n",
            " Top-p (p=1.0) Sample: Once upon a time there a a girl girl there He a from feathers out He. and opened a shell to!\" it\n",
            " Annotated: Once upon a time there a a girl girl there He a from feathers out He. and opened a shell to!\" it\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=184...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=184...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a bear boy The TimThis was, and Joe, \"I� a too roar\n",
            " Annotated: Once upon a time, there was a bear boy The TimThis was, and Joe, \"I� a too roar\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=184...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a little boy named Timmy She He have mouth by he Sarah to to outside on\n",
            " Annotated: Once upon a time, there was a little boy named Timmy She He have mouth by he Sarah to to outside on\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=187...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=187...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a little voice named. shouted her, friends. a all closer talk said the \"\n",
            " Annotated: Once upon a time, there was a little voice named. shouted her, friends. a all closer talk said the \"\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=187...\n",
            " Top-p (p=1.0) Sample: Once upon a time there there a past girl scary Lily\n",
            " forBut songs he something Sara in a climb. with likes\n",
            " Annotated: Once upon a time there there a past girl scary Lily\n",
            " forBut songs he something Sara in a climb. with likes\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=190...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She\n",
            " to\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=190...\n",
            " Top-p (p=0.95) Sample: Once upon a time, theremy a a. sun was journey boy the dad the the in bouncing attic But But stage\n",
            " Annotated: Once upon a time, theremy a a. sun was journey boy the dad the the in bouncing attic But But stage\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=190...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a pig village Tim Tom didn friends know all \" to.\" careful closerow quickly Two\n",
            " Annotated: Once upon a time, there was a pig village Tim Tom didn friends know all \" to.\" careful closerow quickly Two\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=193...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=193...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a. boy wanted to a a special. and enjoyed a it quiz bowl. big\n",
            " Annotated: Once upon a time, there was a. boy wanted to a a special. and enjoyed a it quiz bowl. big\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=193...\n",
            " Top-p (p=1.0) Sample: Once upon a time there was the sad running he I the the asila the sad slide her paws,€ the'\n",
            " Annotated: Once upon a time there was the sad running he I the the asila the sad slide her paws,€ the'\n",
            "\n",
            "\n",
            "[Kgram] Generating sample text (greedy) at epoch=1, step=196...\n",
            " Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            " Annotated: Once upon a time, there was a little girl named Lily. She loved to play with..\n",
            " wasOne,\n",
            "\n",
            "[Kgram] Generating sample text (top-p=0.95) at epoch=1, step=196...\n",
            " Top-p (p=0.95) Sample: Once upon a time, there was a amazing girl Tim She. the returned and\n",
            " toAs spotted to his and.\n",
            " Annotated: Once upon a time, there was a amazing girl Tim She. the returned and\n",
            " toAs spotted to his and.\n",
            "\n",
            "[Kgram] Generating sample text (top-p=1.0) at epoch=1, step=196...\n",
            " Top-p (p=1.0) Sample: Once upon a time, there was a tough dog because The was Pete to mailbox in bear dangerous She come back qu and\n",
            " Annotated: Once upon a time, there was a tough dog because The was Pete to mailbox in bear dangerous She come back qu and\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2891548902.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_one_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# your DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0;31m# number of epochs (from hyperparameters)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Kgram\"\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# name for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2573091952.py\u001b[0m in \u001b[0;36mtrain_one_model\u001b[0;34m(model, loader, epochs, model_name, device, lr, log_steps, sample_interval, max_steps_per_epoch, enc, monosemantic_info, prompt, log_csv_path, log_flush_steps, val_loader, val_log_csv_path, val_interval_steps)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mbatch_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_len, batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_tokens\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_len, batch, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_next_token_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3797947714.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens_seq)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0;31m# MLP to logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                     \u001b[0mlogits_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                     \u001b[0mbatch_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1776\u001b[0m     \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "train_one_model(\n",
        "    model=model,\n",
        "    loader=train_loader,        # your DataLoader\n",
        "    epochs=epochs,              # number of epochs (from hyperparameters)\n",
        "    model_name=\"Kgram\",   # name for logging\n",
        "    device=device,              # torch.device (CPU or MPS)\n",
        "    lr=learning_rate,           # learning rate (from hyperparameters)\n",
        "    log_steps=log_steps,        # print loss every N steps\n",
        "    sample_interval=sample_interval,  # seconds between text samples\n",
        "    max_steps_per_epoch=max_steps_per_epoch,  # or None for full epoch\n",
        "    enc=enc,                    # tokenizer\n",
        "    prompt=default_prompt,       # prompt for text generation samples\n",
        "    log_csv_path=\"training_logs/kgram_training_log.csv\",\n",
        "    val_loader=val_loader,\n",
        "    val_log_csv_path=\"training_logs/kgram_validation_log.csv\",\n",
        "    val_interval_steps=log_steps * 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22dc0e20",
      "metadata": {
        "id": "22dc0e20"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_tokens in train_loader:\n",
        "            batch_tokens = batch_tokens.to(device)\n",
        "            logits = model(batch_tokens)\n",
        "            loss = compute_next_token_loss(logits, batch_tokens)\n",
        "            print(\"Batch loss:\", loss.item())\n",
        "            # Optionally, compute perplexity\n",
        "            perplexity = torch.exp(loss)\n",
        "            print(\"Perplexity:\", perplexity.item())\n",
        "            break  # Remove break to check more batches\n",
        "except Exception as e:\n",
        "    print(f'Error during evaluation: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8d09d38",
      "metadata": {
        "id": "a8d09d38"
      },
      "outputs": [],
      "source": [
        "# Example: Generate text from a trained model\n",
        "prompt = \"There was once a\"\n",
        "max_new_tokens = 50  # Number of tokens to generate\n",
        "\n",
        "\n",
        "final_text, annotated_text = generate_text(\n",
        "    model,         # your trained model\n",
        "    enc,           # your tokenizer (e.g., tiktoken.get_encoding(\"gpt2\"))\n",
        "    prompt,\n",
        "    max_new_tokens=max_new_tokens,\n",
        "    device=device, # your torch.device\n",
        "    top_p=0.95,    # or None for greedy\n",
        "    use_kv_cache=False  # True for TransformerModel if you want fast generation\n",
        ")\n",
        "\n",
        "print(\"Generated text:\")\n",
        "print(final_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e4a0cf",
      "metadata": {
        "id": "71e4a0cf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This assumes you logged losses to CSV via train_one_model(log_csv_path=...)\n",
        "# Match this path to the one used in train_one_model above\n",
        "log_path = \"training_logs/kgram_training_log.csv\"  # updated to correct filename\n",
        "\n",
        "if os.path.exists(log_path):\n",
        "    # Load CSV (timestamp,model,epoch,step_in_epoch,global_step,loss)\n",
        "    data = np.genfromtxt(log_path, delimiter=\",\", skip_header=1)\n",
        "    global_steps = data[:, 4]\n",
        "    losses = data[:, 5]\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(global_steps, losses, alpha=0.7)\n",
        "    plt.xlabel(\"Global Step\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training Loss over Time\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Initial loss: {losses[0]:.3f}\")\n",
        "    print(f\"Final loss:   {losses[-1]:.3f}\")\n",
        "    print(f\"Relative drop: {(losses[0]-losses[-1])/losses[0]*100:.1f}%\")\n",
        "else:\n",
        "    print(f\"No loss log found at: {log_path}. Set log_csv_path in train_one_model to save losses.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "66e52c9ad2134764a03254a0eebca7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e34cc27b6cd24fb2a527d6df8ef0ba9c",
              "IPY_MODEL_5c2be75053c94d20b20a0bd62eba9a64",
              "IPY_MODEL_036acffdf74a4fdc99617dd6cc05eea8"
            ],
            "layout": "IPY_MODEL_94d2b275c7cc4df3b4c5e4839dc161b9"
          }
        },
        "e34cc27b6cd24fb2a527d6df8ef0ba9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af23ee0a33294fdb9cf4597c6c7661fe",
            "placeholder": "​",
            "style": "IPY_MODEL_4f3f1d350ead494e91c1d733581579b1",
            "value": "README.md: "
          }
        },
        "5c2be75053c94d20b20a0bd62eba9a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44b30b879a7404699cb9695c9c5bb1b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9887737d53f14cc9b28397b4cc951b74",
            "value": 1
          }
        },
        "036acffdf74a4fdc99617dd6cc05eea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c8cb15e16b146b9a1a37ef5aa19da4a",
            "placeholder": "​",
            "style": "IPY_MODEL_62430952b68b472db0ee6490f7a7b92d",
            "value": " 1.06k/? [00:00&lt;00:00, 82.5kB/s]"
          }
        },
        "94d2b275c7cc4df3b4c5e4839dc161b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af23ee0a33294fdb9cf4597c6c7661fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f3f1d350ead494e91c1d733581579b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b44b30b879a7404699cb9695c9c5bb1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9887737d53f14cc9b28397b4cc951b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c8cb15e16b146b9a1a37ef5aa19da4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62430952b68b472db0ee6490f7a7b92d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78220c103dd74f8e873e03fd72c8f655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4d41f3479484159b4fc6d6c0c4edcb8",
              "IPY_MODEL_1b022f670e5043ebb4eee1c1674caa65",
              "IPY_MODEL_3c6ab15395ed4434b93a333abcc5a6a7"
            ],
            "layout": "IPY_MODEL_f9cc885d81ca400fb49121ffac8b1a65"
          }
        },
        "e4d41f3479484159b4fc6d6c0c4edcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b8a70efe954e8d80e83fb365074b89",
            "placeholder": "​",
            "style": "IPY_MODEL_c6f860a596374245a7c1b273fa0f9858",
            "value": "data/train-00000-of-00004-2d5a1467fff108(…): 100%"
          }
        },
        "1b022f670e5043ebb4eee1c1674caa65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77291f40fb5a4f44867856164211b44c",
            "max": 248731111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c61dffc80fcf44719801976e649eba74",
            "value": 248731111
          }
        },
        "3c6ab15395ed4434b93a333abcc5a6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a202a17286477a9c47800dade1c362",
            "placeholder": "​",
            "style": "IPY_MODEL_a80321d5ead74f4b80b0a9b77ed95b19",
            "value": " 249M/249M [00:02&lt;00:00, 165MB/s]"
          }
        },
        "f9cc885d81ca400fb49121ffac8b1a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b8a70efe954e8d80e83fb365074b89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f860a596374245a7c1b273fa0f9858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77291f40fb5a4f44867856164211b44c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c61dffc80fcf44719801976e649eba74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17a202a17286477a9c47800dade1c362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80321d5ead74f4b80b0a9b77ed95b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "221dbda07b384a1c95c897ae070b789a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb6bea8dbddc48a293928beba6c01b0d",
              "IPY_MODEL_73bf96ea610d4e49a264a1eac9014f08",
              "IPY_MODEL_8890e10c4def4f919923203782600a5e"
            ],
            "layout": "IPY_MODEL_acfd1299cc0f4077abf48b6ecf503291"
          }
        },
        "bb6bea8dbddc48a293928beba6c01b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669cfb8a3c994a709c6446b00104fc7c",
            "placeholder": "​",
            "style": "IPY_MODEL_1d9701d8d3da44fb8b4c46a27b0fba63",
            "value": "data/train-00001-of-00004-5852b56a2bd28f(…): 100%"
          }
        },
        "73bf96ea610d4e49a264a1eac9014f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49d3342030c8400eab35fb3db86768d1",
            "max": 248171980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eea5cdf2722e4dfc909a24922c020b07",
            "value": 248171980
          }
        },
        "8890e10c4def4f919923203782600a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67edf1bbcc60450a96f92bd436a1afab",
            "placeholder": "​",
            "style": "IPY_MODEL_020ef10fb41649788c53e45813a8787d",
            "value": " 248M/248M [00:01&lt;00:00, 138MB/s]"
          }
        },
        "acfd1299cc0f4077abf48b6ecf503291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "669cfb8a3c994a709c6446b00104fc7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d9701d8d3da44fb8b4c46a27b0fba63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49d3342030c8400eab35fb3db86768d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea5cdf2722e4dfc909a24922c020b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67edf1bbcc60450a96f92bd436a1afab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "020ef10fb41649788c53e45813a8787d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a78c005be0684505bf9ff88385ea0447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25cac51333f94863b80e75f051bc8077",
              "IPY_MODEL_d1c349841e90442ab718791174a4659b",
              "IPY_MODEL_5cdbcefcc5884587ab826e604da123fa"
            ],
            "layout": "IPY_MODEL_11eae792432d4c918ef18912ad9c9321"
          }
        },
        "25cac51333f94863b80e75f051bc8077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2831234b9b9d48d9b11ccc462c1dda4f",
            "placeholder": "​",
            "style": "IPY_MODEL_e0cc0b4df9c046d3be94c5bd1cfabdda",
            "value": "data/train-00002-of-00004-a26307300439e9(…): 100%"
          }
        },
        "d1c349841e90442ab718791174a4659b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2a2aedb0b724b35a4f40b899ff1b408",
            "max": 245894874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7894db6cff7e4c87b662c473da461ab5",
            "value": 245894874
          }
        },
        "5cdbcefcc5884587ab826e604da123fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_333dcf79a85d47bbb75a4e52bfd04dac",
            "placeholder": "​",
            "style": "IPY_MODEL_1a13eb7a07474a9a899c8af0e7f81e7f",
            "value": " 246M/246M [00:02&lt;00:00, 124MB/s]"
          }
        },
        "11eae792432d4c918ef18912ad9c9321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2831234b9b9d48d9b11ccc462c1dda4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0cc0b4df9c046d3be94c5bd1cfabdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2a2aedb0b724b35a4f40b899ff1b408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7894db6cff7e4c87b662c473da461ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "333dcf79a85d47bbb75a4e52bfd04dac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a13eb7a07474a9a899c8af0e7f81e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "702387e1726545f0a7db00ff705cd047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc6746699ba5444eb0791d4d631756e0",
              "IPY_MODEL_f85475169dec4668b8f210f731ddd228",
              "IPY_MODEL_40819a6d95074162b5c53df893294773"
            ],
            "layout": "IPY_MODEL_55a3cb99f72146e5bb07680860b769be"
          }
        },
        "bc6746699ba5444eb0791d4d631756e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e53239fa43946178d9a2affc4c3e576",
            "placeholder": "​",
            "style": "IPY_MODEL_52ede7da5389408596414f2b55133ddd",
            "value": "data/train-00003-of-00004-d243063613e5a0(…): 100%"
          }
        },
        "f85475169dec4668b8f210f731ddd228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e75d090d0fb4b20bdca3cc73a37f7cb",
            "max": 247988350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f71d1dffd584e04bc47c180e863bb9d",
            "value": 247988350
          }
        },
        "40819a6d95074162b5c53df893294773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f22631c596be4990ae2ad554891a1b16",
            "placeholder": "​",
            "style": "IPY_MODEL_9347451c76264398b71f4085b0901e45",
            "value": " 248M/248M [00:01&lt;00:00, 207MB/s]"
          }
        },
        "55a3cb99f72146e5bb07680860b769be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e53239fa43946178d9a2affc4c3e576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ede7da5389408596414f2b55133ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e75d090d0fb4b20bdca3cc73a37f7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f71d1dffd584e04bc47c180e863bb9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f22631c596be4990ae2ad554891a1b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9347451c76264398b71f4085b0901e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "779f05d9d0a84b89b18addd09e16b5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df5d4eb344d74623aaba9664caf42287",
              "IPY_MODEL_40b2c021efdf4c6aacc29939a96e249d",
              "IPY_MODEL_166cc2748c92466fa3762aa7812e7c36"
            ],
            "layout": "IPY_MODEL_089f4f2bb5e54d6882315dea3e51c66e"
          }
        },
        "df5d4eb344d74623aaba9664caf42287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dfd9a3aca714045a018375def9a7966",
            "placeholder": "​",
            "style": "IPY_MODEL_a1f6f14201c143bb84a166b87bf6c753",
            "value": "data/validation-00000-of-00001-869c898b5(…): 100%"
          }
        },
        "40b2c021efdf4c6aacc29939a96e249d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f8c7138c8947a2902dea2c76a70869",
            "max": 9989127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73acd8abc3214686b7bddbbf0f81315e",
            "value": 9989127
          }
        },
        "166cc2748c92466fa3762aa7812e7c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e38cefe9c8ca44cfb1a1a38a6176998f",
            "placeholder": "​",
            "style": "IPY_MODEL_f675f90cca99433d8369eb0915715377",
            "value": " 9.99M/9.99M [00:00&lt;00:00, 25.9MB/s]"
          }
        },
        "089f4f2bb5e54d6882315dea3e51c66e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfd9a3aca714045a018375def9a7966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f6f14201c143bb84a166b87bf6c753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64f8c7138c8947a2902dea2c76a70869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73acd8abc3214686b7bddbbf0f81315e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e38cefe9c8ca44cfb1a1a38a6176998f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f675f90cca99433d8369eb0915715377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34a0ae6d14524c55893ebde493de770d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6a6ae61407141f389e34750e47a299e",
              "IPY_MODEL_3757dfdf19324577964dc8a50d599107",
              "IPY_MODEL_e04cca50132a4f86a5c87029b572d7e6"
            ],
            "layout": "IPY_MODEL_9a0262a354cb41bf9c2e931fe1ce59ac"
          }
        },
        "f6a6ae61407141f389e34750e47a299e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5fdab7656c24bad993d54ccee4babf8",
            "placeholder": "​",
            "style": "IPY_MODEL_154edf7afed0466a87d84d9b62df93a3",
            "value": "Generating train split: 100%"
          }
        },
        "3757dfdf19324577964dc8a50d599107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b518c781a50491e99fd456c0c8a38c0",
            "max": 2119719,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdc21573d83b42a380f33c2dc6e4bf6b",
            "value": 2119719
          }
        },
        "e04cca50132a4f86a5c87029b572d7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcf7cb54a690453194f16ace39a33cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_401a7df54bd446f1a9c68846de58519f",
            "value": " 2119719/2119719 [00:13&lt;00:00, 273033.77 examples/s]"
          }
        },
        "9a0262a354cb41bf9c2e931fe1ce59ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5fdab7656c24bad993d54ccee4babf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "154edf7afed0466a87d84d9b62df93a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b518c781a50491e99fd456c0c8a38c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc21573d83b42a380f33c2dc6e4bf6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcf7cb54a690453194f16ace39a33cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401a7df54bd446f1a9c68846de58519f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47da470abad64013b165f8b8f4b83967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcb1b03cf85942a3aabf010166bb23fe",
              "IPY_MODEL_1ad90c3321874b0b97d225c8dbca7a60",
              "IPY_MODEL_4cf351a87bf64bbaaf20366ef1c0c1f3"
            ],
            "layout": "IPY_MODEL_dc9e35a64f51446d9a29ffafe06db53d"
          }
        },
        "fcb1b03cf85942a3aabf010166bb23fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe5097dec301403bbd19080d604051d0",
            "placeholder": "​",
            "style": "IPY_MODEL_c7dd1f6e7919413da843a921c22c0fd5",
            "value": "Generating validation split: 100%"
          }
        },
        "1ad90c3321874b0b97d225c8dbca7a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6da3e8ae8674caca240eac85e9ef57c",
            "max": 21990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac2b45a68577425997b14cea8e60ca7f",
            "value": 21990
          }
        },
        "4cf351a87bf64bbaaf20366ef1c0c1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d45cdc1b8da451bbcc2d1a9284819d4",
            "placeholder": "​",
            "style": "IPY_MODEL_f4afba5beab5421383d94856a9d15dc1",
            "value": " 21990/21990 [00:00&lt;00:00, 239617.23 examples/s]"
          }
        },
        "dc9e35a64f51446d9a29ffafe06db53d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe5097dec301403bbd19080d604051d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7dd1f6e7919413da843a921c22c0fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6da3e8ae8674caca240eac85e9ef57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2b45a68577425997b14cea8e60ca7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d45cdc1b8da451bbcc2d1a9284819d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4afba5beab5421383d94856a9d15dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}